- id: 1
  authors:
  - first_name: Shafiq
    last_name: Joty
  - first_name: Enamul
    last_name: Hoque
  - first_name: Jesse
    last_name: Vig
  title: 'NLP+Vis: NLP Meets Visualization'
  file: 5_Paper.pdf
  abstract: 'Natural language and visualization (Vis) are two powerful modalities of human communication. The goal of this tutorial is to push forward the agenda of tightly integrating these two modalities. To this end, the tutorial will introduce NLP+Vis with a focus on two main threads of work: \textit{(i) NLP for Vis:} How to develop and adapt state-of-the-art NLP models for solving various visualization tasks? and \textit{(ii) Vis for NLP:} How to leverage visualization techniques to interpret and explain complex NLP models effectively? The tutorial will first motivate why NLP+Vis is an important area of research and provide an overview of research topics on combining NLP and Vis techniques. Then an overview of state-of-the-art deep learning models for NLP will be covered. Next, we will provide an overview of applying visualization techniques to help make NLP models more interpretable and explainable. In the final part, we will focus on various application tasks at the intersection of NLP and Vis. We will conclude with an interactive discussion of future challenges for NLP+Vis applications. The audience will include researchers interested in applying NLP for visualizations as well as others who focus more generally at the intersection of machine learning and visualization.'
- id: 2
  authors:
  - first_name: Qiongkai
    last_name: Xu
  - first_name: Xuanli
    last_name: He
  title: Security Challenges in Natural Language Processing Models
  file: 11_Paper.pdf
  abstract: Large-scale natural language processing models have been developed and integrated into numerous applications, given the advantage of their remarkable performance. Nonetheless, the security concerns associated with these models prevent the widespread adoption of these black-box machine learning models. In this tutorial, we will dive into three emerging security issues in NLP research, i.e., backdoor attacks, private data leakage, and imitation attacks. These threats will be introduced in accordance with their threatening usage scenarios, attack methodologies, and defense technologies.
- id: 3
  authors:
  - first_name: Tongshuang
    last_name: Wu
  - first_name: Diyi
    last_name: Yang
  - first_name: Sebastin
    last_name: Santy
  title: Designing, Evaluating, and Learning from Humans Interacting with NLP Models
  file: 14_Paper.pdf
  abstract: ''
- id: 4
  authors:
  - first_name: Wenpeng
    last_name: Yin
  - first_name: Qinyuan
    last_name: Ye
  - first_name: Pengfei
    last_name: Liu
  - first_name: Xiang
    last_name: Ren
  - first_name: Hinrich
    last_name: Sch{\"u}tze
  title: 'LLM-driven Instruction Following: Progresses and Concerns'
  file: 16_Paper.pdf
  abstract: 'The progress of natural language processing (NLP) is primarily driven by machine learning that optimizes a system on a large-scale set of task-specific labeled examples. This learning paradigm limits the ability of machines to have the same capabilities as humans in handling new tasks since humans can often solve unseen tasks with a couple of examples accompanied by task instructions. In addition, we may not have a chance to prepare task-specific examples of large-volume for new tasks because we cannot foresee what task needs to be addressed next and how complex to annotate for it. Therefore, task instructions act as a novel and promising resource for supervision. This tutorial targets researchers and practitioners who are interested in AI and ML technologies for NLP generalization in a low-shot scenario. In particular, we will present a diverse thread of instruction-driven NLP studies that try to answer the following questions: (i) What is task instruction? (ii) How is the process of creating datasets and evaluating systems conducted? (iii) How to encode task instructions? (iv) When and why do some instructions work better? (v) What concerns remain in LLM-driven instruction following? We will discuss several lines of frontier research that tackle those challenges and will conclude the tutorial by outlining directions for further investigation.'
- id: 5
  authors:
  - first_name: Sachin
    last_name: Kumar
  - first_name: Vidhisha
    last_name: Balachandran
  - first_name: Lucille
    last_name: Njoo
  - first_name: Antonios
    last_name: Anastasopoulos
  - first_name: Yulia
    last_name: Tsvetkov
  title: Mitigating Societal Harms in Large Language Models
  file: 26_Paper.pdf
  abstract: Numerous recent studies have highlighted societal harms that can be caused by language technologies deployed in the wild. While several surveys, tutorials, and workshops have discussed the risks of harms in specific contexts -- e.g., detecting and mitigating gender bias in NLP models -- no prior work has developed a unified typology of technical approaches for mitigating harms of language generation models. Our tutorial is based on a survey we recently wrote that proposes such a typology. We will provide an overview of potential social issues in language generation, including toxicity, social biases, misinformation, factual inconsistency, and privacy violations. Our primary focus will be on how to systematically identify risks, and how eliminate them at various stages of model development, from data collection, to model development, to inference/language generation. Through this tutorial, we aim to equip NLP researchers and engineers with a suite of practical tools for mitigating safety risks from pretrained language generation models.
- id: 6
  authors:
  - first_name: Tuhin
    last_name: Chakrabarty
  - first_name: Vishakh
    last_name: Padmakumar
  - first_name: He
    last_name: He
  - first_name: Nanyun
    last_name: Peng
  title: Creative Natural Language Generation
  file: 42_Paper.pdf
  abstract: ''
